{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be04d77a-3d5a-4ca1-9922-bccfa9b8c6c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mediapipe in d:\\conda_envs\\lipnet\\lib\\site-packages (0.10.31)\n",
      "Requirement already satisfied: absl-py~=2.3 in d:\\conda_envs\\lipnet\\lib\\site-packages (from mediapipe) (2.3.1)\n",
      "Requirement already satisfied: numpy in d:\\conda_envs\\lipnet\\lib\\site-packages (from mediapipe) (2.2.6)\n",
      "Requirement already satisfied: sounddevice~=0.5 in d:\\conda_envs\\lipnet\\lib\\site-packages (from mediapipe) (0.5.3)\n",
      "Requirement already satisfied: flatbuffers~=25.9 in d:\\conda_envs\\lipnet\\lib\\site-packages (from mediapipe) (25.9.23)\n",
      "Requirement already satisfied: CFFI>=1.0 in d:\\conda_envs\\lipnet\\lib\\site-packages (from sounddevice~=0.5->mediapipe) (2.0.0)\n",
      "Requirement already satisfied: pycparser in d:\\conda_envs\\lipnet\\lib\\site-packages (from CFFI>=1.0->sounddevice~=0.5->mediapipe) (2.23)\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install mediapipe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed676ba9-95c2-4ee9-8553-f7a7363315fe",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mediapipe'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmediapipe\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmp\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'mediapipe'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas\n",
    "import cv2\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import mediapipe as mp\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30dc93b7-9991-4894-9fcd-49ec9dd8dec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap=cv2.VideoCapture(r\"C:\\Users\\ronak\\OneDrive\\Desktop\\bbaf2n.mpg\")\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open video.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3748b1-6e26-4003-984d-56594f95114a",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames=[]\n",
    "res=[]\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    frames.append(frame)\n",
    "    res.append(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19349dd8-0512-4860-8e84-c09b1f2e5ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb = cv2.cvtColor(frames[0], cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.imshow(rgb)\n",
    "plt.axis('off')  # hide axes\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85b2a6f-e804-4488-912b-c1d09f3e4b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import vision\n",
    "\n",
    "base_options = python.BaseOptions(\n",
    "    model_asset_path=r\"C:\\Users\\ronak\\Downloads\\face_landmarker.task\"\n",
    ")\n",
    "\n",
    "\n",
    "options = vision.FaceLandmarkerOptions(\n",
    "    base_options=base_options,\n",
    "    num_faces=1\n",
    ")\n",
    "\n",
    "\n",
    "detector = vision.FaceLandmarker.create_from_options(options)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b700dbc7-1550-44a0-9e41-d5542ee7cc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_image = mp.Image(\n",
    "        image_format=mp.ImageFormat.SRGB,\n",
    "        data=rgb\n",
    "    )\n",
    "\n",
    "result = detector.detect(mp_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141e163d-0726-4ba6-b980-340172305fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.face_landmarks[0][0].x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724c93c1-1b49-474f-b272-82db6f091d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MediaPipe lip landmark indices\n",
    "LIPS = [\n",
    "    61, 146, 91, 181, 84, 17, 314, 405,\n",
    "    321, 375, 291, 308, 324, 318, 402,\n",
    "    317, 14, 87, 178, 88, 95, 185,\n",
    "    40, 39, 37, 0, 267, 269, 270,\n",
    "    409, 415, 310, 311, 312, 13,\n",
    "    82, 81, 42, 183, 78\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa01bd83-7703-4c07-8835-9d6ec98de7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import vision\n",
    "\n",
    "# ---------- Load FaceLandmarker ----------\n",
    "base_options = python.BaseOptions(\n",
    "    model_asset_path=r\"C:\\Users\\ronak\\Downloads\\face_landmarker.task\"\n",
    ")\n",
    "\n",
    "options = vision.FaceLandmarkerOptions(\n",
    "    base_options=base_options,\n",
    "    num_faces=1\n",
    ")\n",
    "\n",
    "detector = vision.FaceLandmarker.create_from_options(options)\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(r\"C:\\Users\\ronak\\OneDrive\\Desktop\\bbaf2n.mpg\")\n",
    "\n",
    "mouth_frames = []\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    h, w, _ = frame.shape\n",
    "    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    mp_image = mp.Image(\n",
    "        image_format=mp.ImageFormat.SRGB,\n",
    "        data=rgb\n",
    "    )\n",
    "\n",
    "    result = detector.detect(mp_image)\n",
    "\n",
    "    if not result.face_landmarks:\n",
    "        continue\n",
    "\n",
    "    landmarks = result.face_landmarks[0]\n",
    "\n",
    "    xs = [int(landmarks[i].x * w) for i in LIPS]\n",
    "    ys = [int(landmarks[i].y * h) for i in LIPS]\n",
    "\n",
    "    x_min, x_max = min(xs), max(xs)\n",
    "    y_min, y_max = min(ys), max(ys)\n",
    "\n",
    "    mouth = frame[y_min:y_max, x_min:x_max]\n",
    "\n",
    "    # Grayscale + resize (LipNet standard)\n",
    "    mouth = cv2.cvtColor(mouth, cv2.COLOR_BGR2GRAY)\n",
    "    mouth = cv2.resize(mouth, (100, 50))\n",
    "\n",
    "    mouth_frames.append(mouth)\n",
    "\n",
    "cap.release()\n",
    "\n",
    "print(\"Total mouth frames:\", len(mouth_frames))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e07f18-9696-4f42-8162-f8101a7ae4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(mouth, cmap=\"gray\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4cf8afa",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mediapipe'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcv2\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmediapipe\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmp\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmediapipe\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtasks\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m python\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmediapipe\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtasks\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m vision\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'mediapipe'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import vision\n",
    "\n",
    "class Frames():\n",
    "    def __init__(self,model_path):\n",
    "        base_options = python.BaseOptions(\n",
    "            model_asset_path=model_path)\n",
    "        options = vision.FaceLandmarkerOptions(\n",
    "            base_options=base_options,\n",
    "            num_faces=1\n",
    "        )\n",
    "        self.detector = vision.FaceLandmarker.create_from_options(options)\n",
    "\n",
    "\n",
    "        # MediaPipe lip landmark indices\n",
    "        self.LIPS = [\n",
    "            61, 146, 91, 181, 84, 17, 314, 405,\n",
    "            321, 375, 291, 308, 324, 318,\n",
    "            402, 317, 14, 87, 178, 88\n",
    "        ]\n",
    "        self.FEAT_DIM = len(self.LIPS) * 3 \n",
    "\n",
    "    def extract_mouth_frames(self,video_path):\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "        frame_features = []\n",
    "        \n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "        \n",
    "            h, w, _ = frame.shape\n",
    "            rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "            mp_image = mp.Image(\n",
    "                image_format=mp.ImageFormat.SRGB,\n",
    "                data=rgb\n",
    "            )\n",
    "        \n",
    "            result = self.detector.detect(mp_image)\n",
    "        \n",
    "            if not result.face_landmarks:\n",
    "                continue\n",
    "        \n",
    "            face_landmarks = result.face_landmarks[0]\n",
    "\n",
    "            landmarks = []\n",
    "            for idx in self.LIPS:\n",
    "                lm = face_landmarks[idx]\n",
    "                landmarks.extend([lm.x, lm.y, lm.z])\n",
    "\n",
    "            frame_feat = torch.tensor(landmarks)\n",
    "\n",
    "            if frame_feat.numel() == self.FEAT_DIM:\n",
    "                frame_features.append(frame_feat)\n",
    "            # xs = [int(landmarks[i].x * w) for i in self.LIPS]\n",
    "            # ys = [int(landmarks[i].y * h) for i in self.LIPS]\n",
    "        \n",
    "            # x_min, x_max = min(xs), max(xs)\n",
    "            # y_min, y_max = min(ys), max(ys)\n",
    "        \n",
    "            # mouth = frame[y_min:y_max, x_min:x_max]\n",
    "        \n",
    "            \n",
    "            # mouth = cv2.cvtColor(mouth, cv2.COLOR_BGR2GRAY)\n",
    "            # mouth = cv2.resize(mouth, (100, 50))\n",
    "        \n",
    "            # mouth_frames.append(mouth)\n",
    "        \n",
    "        cap.release()\n",
    "        \n",
    "\n",
    "        if len(frame_features) == 0:\n",
    "            return None\n",
    "\n",
    "        # Shape: [T, 60]\n",
    "        return torch.stack(frame_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6d36822-aa74-4ad6-8fd4-7872219ebe28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ronak\\anaconda3\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c19cea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames=Frames(\"C:\\Users\\ronak\\Downloads\\face_landmarker.task\")\n",
    "a=frames.extract_mouth_frames(\"C:\\Users\\ronak\\OneDrive\\Desktop\\bbaf2n.mpg\")\n",
    "plt.imshow(a, cmap=\"gray\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc595601-144c-452e-bfa8-3872c418292e",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_options = python.BaseOptions(\n",
    "    model_asset_path=r\"C:\\Users\\ronak\\Downloads\\face_landmarker.task\"\n",
    ")\n",
    "\n",
    "options = vision.FaceLandmarkerOptions(\n",
    "    base_options=base_options,\n",
    "    num_faces=1\n",
    ")\n",
    "\n",
    "detector = vision.FaceLandmarker.create_from_options(options)\n",
    "\n",
    "\n",
    "# MediaPipe lip landmark indices\n",
    "LIPS = [\n",
    "    61, 146, 91, 181, 84, 17, 314, 405,\n",
    "    321, 375, 291, 308, 324, 318, 402,\n",
    "    317, 14, 87, 178, 88, 95, 185,\n",
    "    40, 39, 37, 0, 267, 269, 270,\n",
    "    409, 415, 310, 311, 312, 13,\n",
    "    82, 81, 42, 183, 78\n",
    "]\n",
    "\n",
    "\n",
    "def extract_mouth_frames(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    mouth_frames = []\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "    \n",
    "        h, w, _ = frame.shape\n",
    "        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "        mp_image = mp.Image(\n",
    "            image_format=mp.ImageFormat.SRGB,\n",
    "            data=rgb\n",
    "        )\n",
    "    \n",
    "        result = detector.detect(mp_image)\n",
    "    \n",
    "        if not result.face_landmarks:\n",
    "            continue\n",
    "    \n",
    "        landmarks = result.face_landmarks[0]\n",
    "    \n",
    "        xs = [int(landmarks[i].x * w) for i in LIPS]\n",
    "        ys = [int(landmarks[i].y * h) for i in LIPS]\n",
    "    \n",
    "        x_min, x_max = min(xs), max(xs)\n",
    "        y_min, y_max = min(ys), max(ys)\n",
    "    \n",
    "        mouth = frame[y_min:y_max, x_min:x_max]\n",
    "    \n",
    "        \n",
    "        mouth = cv2.cvtColor(mouth, cv2.COLOR_BGR2GRAY)\n",
    "        mouth = cv2.resize(mouth, (100, 50))\n",
    "    \n",
    "        mouth_frames.append(mouth)\n",
    "    \n",
    "    cap.release()\n",
    "    \n",
    "\n",
    "    return mouth_frames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03bc9355-2c43-483e-8d2e-a6e1f127a6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_align(path):\n",
    "    words=[]\n",
    "    with open(path,'r') as fobj:\n",
    "        for line in fobj:\n",
    "            _,_,word=line.strip().split()\n",
    "            if word!= \"sil\":\n",
    "                words.append(word)\n",
    "    return \" \".join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bca5ff7-246c-4d00-a2da-5d860b51618f",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=decode_align(r\"C:\\Users\\ronak\\OneDrive\\Desktop\\bbaf2n.align\")\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea12c959-2bae-4134-9256-c0ca5d201659",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = list(\"abcdefghijklmnopqrstuvwxyz1234567890!ABCDEFGHIJKLMNOPQRSTUVWXYZ \")\n",
    "char_to_idx = {c: i+1 for i, c in enumerate(vocab)}  # 0 reserved for CTC blank\n",
    "idx_to_char = {i: c for c, i in char_to_idx.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910a481b-8051-4a7f-9d26-0d7e9f74bd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_labels(text):\n",
    "    output=[]\n",
    "    for c in text:\n",
    "        output.append(char_to_idx[c])\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ba94cb-dd2f-40e4-ad0b-050d156f7571",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_to_labels(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d4e827-aaf3-421a-a4e8-df1a9ba1b630",
   "metadata": {},
   "outputs": [],
   "source": [
    "path=r\"C:\\Users\\ronak\\OneDrive\\Desktop\\data\"\n",
    "alignment_path=os.path.join(path,\"alignments\",\"s1\")\n",
    "speaker_path=os.path.join(path,\"s1\")\n",
    "iterable=zip(os.listdir(alignment_path),os.listdir(speaker_path))\n",
    "def load_data(path,iterable, batch_size=16):\n",
    "    all_align = []\n",
    "    all_video_frames = []\n",
    "    alignment_path=os.path.join(path,\"alignments\",\"s1\")\n",
    "    speaker_path=os.path.join(path,\"s1\")\n",
    "    for _ in range(batch_size):\n",
    "        try:\n",
    "            align_file, video_file = next(iterable)\n",
    "\n",
    "            text=decode_align(os.path.join(alignment_path,align_file))\n",
    "            decode_text=text_to_labels(text)\n",
    "\n",
    "            video_file_path=os.path.join(alignment_path,align_file).split(\"\\\\\")[-1][0:-5]+\"mpg\"\n",
    "            \n",
    "            frames=extract_mouth_frames(os.path.join(speaker_path,video_file_path))\n",
    "            \n",
    "            \n",
    "            all_align.append(decode_text)\n",
    "            all_video_frames.append(frames)\n",
    "        except StopIteration:\n",
    "            break\n",
    "\n",
    "    return all_align, all_video_frames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12397f19-40a5-421b-8499-677bdf5ce32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "path=r\"C:\\Users\\ronak\\OneDrive\\Desktop\\data\"\n",
    "alignment_path=os.path.join(path,\"alignments\",\"s1\")\n",
    "speaker_path=os.path.join(path,\"s1\")\n",
    "iterable=zip(os.listdir(alignment_path),os.listdir(speaker_path))\n",
    "a,b=load_data(path,iterable,batch_size=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99ee26c-2161-4638-ade6-113d37fc0e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c263a7a-1a81-4099-83ef-7ac51bbd331c",
   "metadata": {},
   "outputs": [],
   "source": [
    "p=r\"C:\\Users\\ronak\\OneDrive\\Desktop\\data\\alignments\\s1\\bbal7s.align\"\n",
    "p.split(\"\\\\\")[-1][0:-5]+\"mpg\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
