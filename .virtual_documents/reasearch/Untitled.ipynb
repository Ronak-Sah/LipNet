import sys
print(sys.executable)



import cv2
import numpy as np
import mediapipe as mp
from mediapipe.tasks import python
from mediapipe.tasks.python import vision
import torch
class Frames():
    def __init__(self,model_path):
        base_options = python.BaseOptions(
            model_asset_path=model_path)
        options = vision.FaceLandmarkerOptions(
            base_options=base_options,
            num_faces=1
        )
        self.detector = vision.FaceLandmarker.create_from_options(options)


        # MediaPipe lip landmark indices
        self.LIPS = [
            61, 146, 91, 181, 84, 17, 314, 405,
            321, 375, 291, 308, 324, 318,
            402, 317, 14, 87, 178, 88
        ]
        self.FEAT_DIM = len(self.LIPS) * 3 

    def extract_mouth_frames(self,video_path):
        cap = cv2.VideoCapture(video_path)
        H=60
        W=100
        mouth_frames = []
        
        while True:
            ret, frame = cap.read()
            if not ret:
                break
        
            h, w, _ = frame.shape
            rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        
            mp_image = mp.Image(
                image_format=mp.ImageFormat.SRGB,
                data=rgb
            )
        
            result = self.detector.detect(mp_image)
        
            if not result.face_landmarks:
                continue
        
            face_landmarks = result.face_landmarks[0]

            landmarks = []
            xs, ys = [], []
            for idx in self.LIPS:
                lm = face_landmarks[idx]
                xs.append(int(lm.x * w))
                ys.append(int(lm.y * h))
    
            x_min, x_max = max(min(xs)-5,0), min(max(xs)+5, w)
            y_min, y_max = max(min(ys)-5,0), min(max(ys)+5, h)

            mouth_crop = frame[y_min:y_max, x_min:x_max]
            mouth_crop = cv2.cvtColor(mouth_crop, cv2.COLOR_BGR2GRAY)
            mouth_crop = cv2.resize(mouth_crop, (W, H))
    
            mouth_tensor = torch.tensor(mouth_crop, dtype=torch.float32) / 255.0
            mouth_frames.append(mouth_tensor)
            
        
        cap.release()
        

        if len(mouth_frames) == 0:
            return None

        # Shape: [T, 60]
        return torch.stack(mouth_frames)


import matplotlib.pyplot as plt
frames=Frames(r"C:\Users\ronak\Downloads\face_landmarker.task")
a=frames.extract_mouth_frames(r"C:\Users\ronak\OneDrive\Desktop\bbaf2n.mpg")




print(type(a))
print(a.shape)
print(a.dtype)




