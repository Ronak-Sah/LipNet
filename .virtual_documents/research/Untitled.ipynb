import os
import pandas
import cv2
import torch
import matplotlib.pyplot as plt
import mediapipe as mp
import numpy as np



cap=cv2.VideoCapture(r"C:\Users\ronak\OneDrive\Desktop\bbaf2n.mpg")
if not cap.isOpened():
    print("Error: Could not open video.")


frames=[]
res=[]
while True:
    ret, frame = cap.read()
    if not ret:
        break
    frames.append(frame)
    res.append(ret)


rgb = cv2.cvtColor(frames[0], cv2.COLOR_BGR2RGB)

plt.imshow(rgb)
plt.axis('off')  # hide axes
plt.show()



import mediapipe as mp
from mediapipe.tasks import python
from mediapipe.tasks.python import vision

base_options = python.BaseOptions(
    model_asset_path=r"C:\Users\ronak\Downloads\face_landmarker.task"
)


options = vision.FaceLandmarkerOptions(
    base_options=base_options,
    num_faces=1
)


detector = vision.FaceLandmarker.create_from_options(options)





mp_image = mp.Image(
        image_format=mp.ImageFormat.SRGB,
        data=rgb
    )

result = detector.detect(mp_image)


result.face_landmarks[0][0].x


# MediaPipe lip landmark indices
LIPS = [
    61, 146, 91, 181, 84, 17, 314, 405,
    321, 375, 291, 308, 324, 318, 402,
    317, 14, 87, 178, 88, 95, 185,
    40, 39, 37, 0, 267, 269, 270,
    409, 415, 310, 311, 312, 13,
    82, 81, 42, 183, 78
]



import cv2
import numpy as np
import mediapipe as mp
from mediapipe.tasks import python
from mediapipe.tasks.python import vision

# ---------- Load FaceLandmarker ----------
base_options = python.BaseOptions(
    model_asset_path=r"C:\Users\ronak\Downloads\face_landmarker.task"
)

options = vision.FaceLandmarkerOptions(
    base_options=base_options,
    num_faces=1
)

detector = vision.FaceLandmarker.create_from_options(options)


cap = cv2.VideoCapture(r"C:\Users\ronak\OneDrive\Desktop\bbaf2n.mpg")

mouth_frames = []

while True:
    ret, frame = cap.read()
    if not ret:
        break

    h, w, _ = frame.shape
    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)

    mp_image = mp.Image(
        image_format=mp.ImageFormat.SRGB,
        data=rgb
    )

    result = detector.detect(mp_image)

    if not result.face_landmarks:
        continue

    landmarks = result.face_landmarks[0]

    xs = [int(landmarks[i].x * w) for i in LIPS]
    ys = [int(landmarks[i].y * h) for i in LIPS]

    x_min, x_max = min(xs), max(xs)
    y_min, y_max = min(ys), max(ys)

    mouth = frame[y_min:y_max, x_min:x_max]

    # Grayscale + resize (LipNet standard)
    mouth = cv2.cvtColor(mouth, cv2.COLOR_BGR2GRAY)
    mouth = cv2.resize(mouth, (100, 50))

    mouth_frames.append(mouth)

cap.release()

print("Total mouth frames:", len(mouth_frames))



plt.imshow(mouth, cmap="gray")
plt.axis("off")
plt.show()



base_options = python.BaseOptions(
    model_asset_path=r"C:\Users\ronak\Downloads\face_landmarker.task"
)

options = vision.FaceLandmarkerOptions(
    base_options=base_options,
    num_faces=1
)

detector = vision.FaceLandmarker.create_from_options(options)


# MediaPipe lip landmark indices
LIPS = [
    61, 146, 91, 181, 84, 17, 314, 405,
    321, 375, 291, 308, 324, 318, 402,
    317, 14, 87, 178, 88, 95, 185,
    40, 39, 37, 0, 267, 269, 270,
    409, 415, 310, 311, 312, 13,
    82, 81, 42, 183, 78
]


def extract_mouth_frames(video_path):
    cap = cv2.VideoCapture(video_path)

    mouth_frames = []
    
    while True:
        ret, frame = cap.read()
        if not ret:
            break
    
        h, w, _ = frame.shape
        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    
        mp_image = mp.Image(
            image_format=mp.ImageFormat.SRGB,
            data=rgb
        )
    
        result = detector.detect(mp_image)
    
        if not result.face_landmarks:
            continue
    
        landmarks = result.face_landmarks[0]
    
        xs = [int(landmarks[i].x * w) for i in LIPS]
        ys = [int(landmarks[i].y * h) for i in LIPS]
    
        x_min, x_max = min(xs), max(xs)
        y_min, y_max = min(ys), max(ys)
    
        mouth = frame[y_min:y_max, x_min:x_max]
    
        # Grayscale + resize (LipNet standard)
        mouth = cv2.cvtColor(mouth, cv2.COLOR_BGR2GRAY)
        mouth = cv2.resize(mouth, (100, 50))
    
        mouth_frames.append(mouth)
    
    cap.release()
    

    return mouth_frames



def decode_align(path):
    words=[]
    with open(path,'r') as fobj:
        for line in fobj:
            _,_,word=line.strip().split()
            if word!= "sil":
                words.append(word)
    return " ".join(words)


a=decode_align(r"C:\Users\ronak\OneDrive\Desktop\bbaf2n.align")
a


vocab = list("abcdefghijklmnopqrstuvwxyz1234567890!ABCDEFGHIJKLMNOPQRSTUVWXYZ ")
char_to_idx = {c: i+1 for i, c in enumerate(vocab)}  # 0 reserved for CTC blank
idx_to_char = {i: c for c, i in char_to_idx.items()}



def text_to_labels(text):
    output=[]
    for c in text:
        output.append(char_to_idx[c])
    return output



text_to_labels(a)


def load_data(path):
    alignment_path=os.path.join(path,"alignments","s1")
    speaker_path=os.path.join(path,"s1")
    for filename in os.listdir(folder_path):
        


import os
from itertools import chain
pth=r"C:\Users\ronak\OneDrive\Desktop\data"
folder_path=os.path.join(pth,"alignments","s1")
speaker_path=os.path.join(pth,"s1")
iter=chain(os.listdir(folder_path),os.listdir(speaker_path))


iter.__next__()



